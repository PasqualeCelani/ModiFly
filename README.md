# ModiFly
ModiFly is a simulator designed to test a new Human-Drone Interaction (HDI) model that moves beyond traditional, joystick-based interfaces. The project leverages natural human communication modalities, specifically gestures and speech, to create a more intuitive and seamless control experience. The system is designed to be low-cost, easy to use, and capable of running on low-end hardware.

##  :rocket: Key Features
* :large_blue_diamond: **Multimodal interaction:**  integrates two primary modalities such as gestures for continuous drone movement and voice commands for discrete, supportive functions;
* :open_hands: **Two handed gesture control:** A two-handed gesture system is used for handling drone movement, with the left hand controlling position (lateral, altitude, forward/backward) and the right hand controlling rotational yaw;
* :microphone: **Intuitive voice commands:** A set of simple voice commands such as "open", "shut down", "zoom in", "zoom out" and "stop" are used to control system states and camera functions;
* :computer: **Low computational requirements:** The system is designed to be efficient, successfully running on a 2019 MacBook Air with a dual-core i5 processor and 8GB of RAM;
* :seedling: **Natural interaction** The multimodal framework allows for simultaneous, parallel task execution, for example controlling movement with gestures while issuing a voice command, which reduces cognitive load and enhances operational efficiency.

## :paperclip: License 
This project is released under the MIT License.
